{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model Comparison & Selection\n",
                "\n",
                "Benchmarking Logistic Regression, Random Forest, XGBoost, CatBoost, and LightGBM."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "sys.path.append(os.path.abspath('../src'))\n",
                "from data_utils import load_data, split_data\n",
                "from model import RiskModel\n",
                "\n",
                "# Load Real Data\n",
                "data_path = '../data/processed/real_bnpl_features.csv'\n",
                "df = load_data(data_path)\n",
                "target = 'is_default'\n",
                "\n",
                "X = df.drop(columns=[target])\n",
                "y = df[target]\n",
                "X[target] = y\n",
                "X_train_full, X_test_full = split_data(X, target)\n",
                "\n",
                "y_train = X_train_full[target]\n",
                "X_train = X_train_full.drop(columns=[target])\n",
                "y_test = X_test_full[target]\n",
                "X_test = X_test_full.drop(columns=[target])\n",
                "\n",
                "print(f\"Data loaded. Train: {X_train.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "models_to_test = ['logreg', 'rf', 'xgboost', 'catboost', 'lightgbm']\n",
                "results = []\n",
                "\n",
                "for m_type in models_to_test:\n",
                "    print(f\"Training {m_type}...\")\n",
                "    model = RiskModel(model_type=m_type)\n",
                "    try:\n",
                "        model.train(X_train, y_train, X_val=X_test, y_val=y_test)\n",
                "        metrics = model.evaluate(X_test, y_test)\n",
                "        metrics['model'] = m_type\n",
                "        results.append(metrics)\n",
                "        print(f\"  AUC: {metrics['auc']:.4f}\")\n",
                "        \n",
                "        # Save if it's the champion so far, or just strictly 'lightgbm' for prod consistency for now?\n",
                "        # We will select champion based on max AUC at the end\n",
                "    except Exception as e:\n",
                "        print(f\"  Failed: {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results_df = pd.DataFrame(results).sort_values('auc', ascending=False)\n",
                "print(\"\\n--- LEADERBOARD ---\\n\")\n",
                "print(results_df)\n",
                "\n",
                "plt.figure(figsize=(10, 5))\n",
                "sns.barplot(data=results_df, x='model', y='auc')\n",
                "plt.title('Model AUC Comparison')\n",
                "plt.ylim(0.5, 0.8)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save champion\n",
                "champion_name = results_df.iloc[0]['model']\n",
                "print(f\"Champion: {champion_name}\")\n",
                "\n",
                "# Retrain champion on full data or just save the best instance (we didn't keep instances in list, so retrain)\n",
                "final_model = RiskModel(model_type=champion_name)\n",
                "final_model.train(X_train, y_train, X_val=X_test, y_val=y_test)\n",
                "final_model.save('../models/champion_model.pkl')\n",
                "# Also save as the standard 'lightgbm_model.pkl' name if we want to keep app working without code change,\n",
                "# OR update app to load champion. Let's update app later if needed. For now save as generic.\n",
                "final_model.save('../models/risk_model_prod.pkl')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}